{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### К лекции №2\n",
       "\n",
       "**Упражнение №5.0.1**  \n",
       "\n",
       "Освойтесь с NumPy с помощью этого туториала:  \n",
       "\n",
       "https://jakevdp.github.io/PythonDataScienceHandbook/02.00-introduction-to-numpy.html\n",
       "  \n",
       "Перед следующим упражнением, убедитесь что вы понимаете разницу между nparray и стандартным list!  \n",
       "  \n",
       "**Упражнение №5.0.2**  \n",
       "Изучите Pandas - дефакто стандарт для работы с табличными (не bigdata) данными.  \n",
       "\n",
       "https://jakevdp.github.io/PythonDataScienceHandbook/03.01-introducing-pandas-objects.html\n",
       "\n",
       "https://jakevdp.github.io/PythonDataScienceHandbook/03.02-data-indexing-and-selection.html\n",
       "\n",
       "https://jakevdp.github.io/PythonDataScienceHandbook/03.01-introducing-pandas-objects.html \n",
       " \n",
       "**Упражнение №5.1**  \n",
       "\n",
       "Сделайте свой датафрейм на основе 2D-nparray  \n",
       "Он должен поддерживать:  \n",
       "* построчный индекс  \n",
       "* хранить названия и порядок колонок  \n",
       "* функции индексирования:  \n",
       " * iloc[i,j] - получить элемент по i-й строке j-й колонке. (i/j также могут быть slice-объектами)  \n",
       " * loc[k,z] - получить элемент по k-му значению построчного индекса z-й колонке (k может быть iterable/slice, z - iterable)  \n",
       " * [] - переопределить getitem, сделать его алиасом вашей loc-функции  \n",
       "Также нужно сделать статический метод, читающий CSV:   \n",
       "`your_package.read_csv(file_path, **csv_opts)`   \n",
       "и возвращающий инстанс вашего датафрейма с прочитанными данными.    \n",
       "Метод должен принимать параметры, настраивающие поведение чтения CSV-файла.  \n",
       "\n",
       "**Упражнение №6.1**\n",
       "\n",
       "Почитайте про случайный лес в [мануалах scikit](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier)\n",
       "\n",
       "Научитесь обучать лес и запускать его.  \n",
       "Для хранения и передачи данных для sklearn вы должны использовать собственный датафрейм!  \n",
       "\n",
       "**Упражнение №6.2**\n",
       "\n",
       "Научитесь визуализировать деревья. Почитайте:\n",
       "\n",
       "  * [sklearn.tree.export_graphviz](https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html#sklearn.tree.export_graphviz)\n",
       "  * [How to Visualize a Decision Tree from a Random Forest in Python using Scikit-Learn](https://towardsdatascience.com/how-to-visualize-a-decision-tree-from-a-random-forest-in-python-using-scikit-learn-38ad2d75f21c)\n",
       "\n",
       "**Задача №7**\n",
       "\n",
       "Посмотрите на данные из выборки ещё раз. Обучите RF на этих данных.\n",
       "Сравните RF c алгоритмами **p1_fraud**, **p2_fraud** и **p3_fraud**.\n",
       "\n",
       "**Задача №8**\n",
       "\n",
       "Подумайте, как с помощью RF оценивать информативность признаков?\n",
       "Найдите информативные признаки. \n",
       "\n",
       "Сравните результаты с результатами **упражнения №1**.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "with open('lab01.md', 'r') as fh:\n",
    "    content = fh.read()\n",
    "    \n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение №5.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение №5.0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение №5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Блоки с кодом получились довольно жирными и их пришлось разбить. Приписывать импорты к конкретному блоку правильным не считаю, поэтому вынесу в отдельный блок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from collections.abc import Iterable as AbcIterable\n",
    "from typing import Iterable, Sequence, Optional, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Pandas индексация построена на декораторе `property` чтобы сохранить ее в привычно-змеином виде. Геттер `loc`'а/`iloc`'а возвращает объект, который решает как и что делать с полученными ключами/индексами для правильного доступа к вложенным в `DataFrame` данным. В случае индексов думать не нужно - пусть разбирается `np.ndarray`. В случае ключей придется подменить их все на соответствующие им индексы. Реализуем эти объекты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdxView:\n",
    "    def __init__(self, dataframe):\n",
    "        \"\"\"\n",
    "        Integer-index view on Dataframe internal data.\n",
    "        Simply forwards indices to np.ndarray with no checks whatsoever.\n",
    "        \n",
    "        Parameters:\n",
    "            :dataframe: Dataframe\n",
    "                Parent object\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.dataframe.data[key]\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        self.dataframe.data[key] = value\n",
    "        \n",
    "    # TODO(Mocurin): Feels really bad. Should be a way around\n",
    "    def __call__(self, *args):\n",
    "        # Probably a []-get\n",
    "        if len(args) == 1:\n",
    "            return self.__getitem__(*args)\n",
    "        # Probaly a []-set\n",
    "        if len(args) == 2:\n",
    "            return self.__setitem__(*args)\n",
    "        raise ValueError() # TODO\n",
    "    \n",
    "    \n",
    "class KeyView:\n",
    "    def __init__(self, dataframe):\n",
    "        \"\"\"\n",
    "        'Keyed' view on Dataframe internal data.\n",
    "        Converts keys to respective indices and forwards them, to np.ndarray\n",
    "        Note that contrary to usual python slices, both the start and the stop are included\n",
    "        \n",
    "        Parameters\n",
    "            :dataframe: Dataframe\n",
    "                Parent object\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        \n",
    "    def _lookup_key(self, key, axis=0):\n",
    "        \"\"\"\n",
    "        Performs key lookup depending on the axis.\n",
    "        Also supports np.newaxis aka None (which conviniently works for slice\n",
    "        conversions too).\n",
    "        \n",
    "        Parameters\n",
    "            :key: hashable\n",
    "                Key to look up.\n",
    "            :axis: [0, 1]\n",
    "                A value to decide which dict to use for a look up.\n",
    "        \n",
    "        Returns\n",
    "            :: Integer index.\n",
    "            \n",
    "        Raises\n",
    "            :KeyError:\n",
    "                1) Invalid axis (not in [0, 1]).\n",
    "                2) Key is not present in a dict.\n",
    "        \"\"\"\n",
    "        if key is None or isinstance(key, (bool, np.bool_)):\n",
    "            return key\n",
    "        try:\n",
    "            if axis == 0:\n",
    "                return self.dataframe.idx_to_loc[key]\n",
    "            if axis == 1:\n",
    "                return self.dataframe.col_to_loc[key]\n",
    "        except KeyError as e:\n",
    "            e.message = None # TODO\n",
    "            raise e\n",
    "        raise KeyError() # TODO\n",
    "        \n",
    "    def _handle_slice(self, slicing, axis=0):\n",
    "        start = self._lookup_key(slicing.start, axis=axis)\n",
    "        stop = self._lookup_key(slicing.stop, axis=axis)\n",
    "        return slice(start, stop if stop is None else stop + 1, slicing.step)\n",
    "    \n",
    "    def _handle_fancy(self, array, axis=0):\n",
    "        return np.vectorize(lambda x: self._lookup_key(x, axis=axis))(array)\n",
    "    \n",
    "    def _handle_single(self, key, axis=0):\n",
    "        try:\n",
    "            return self._lookup_key(key, axis=axis)\n",
    "        except KeyError as e:\n",
    "            e.message = None # TODO\n",
    "            raise e\n",
    "        \n",
    "    def _axis_handle_pipeline(self, key, axis=0):\n",
    "        if isinstance(key, slice):\n",
    "            return self._handle_slice(key, axis=axis)\n",
    "        if isinstance(key, list) or isinstance(key, np.ndarray):\n",
    "            return self._handle_fancy(key, axis=axis)\n",
    "        return self._handle_single(key, axis=axis)\n",
    "        \n",
    "    def _validate_key(self, key):\n",
    "        \"\"\"\n",
    "        Performs key lookup for: fancy indexing, slicing, singular value\n",
    "        Allows only 1D/2D indexing.\n",
    "        \n",
    "        Parameters\n",
    "            :key: tuple of: slice, sequence, hashable\n",
    "                  or one of: slice, sequence, hashable\n",
    "                Structure with keys to look up.\n",
    "        \n",
    "        Returns\n",
    "            :: key input parameter with integer indices.\n",
    "            \n",
    "        Raises\n",
    "            :KeyError:\n",
    "                Non-1D-or-2D indexing applied.\n",
    "        \"\"\"\n",
    "        # 2D action\n",
    "        if isinstance(key, tuple):\n",
    "            if len(key) != 2:\n",
    "                raise KeyError() # TODO\n",
    "            x_key = self._axis_handle_pipeline(key[0], axis=0)\n",
    "            y_key = self._axis_handle_pipeline(key[1], axis=1)\n",
    "            return (x_key, y_key)\n",
    "        # 1D action\n",
    "        return self._axis_handle_pipeline(key, axis=0)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        return self.dataframe.data[self._validate_key(key)]\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        self.dataframe.data[self._validate_key(key)] = value\n",
    "    \n",
    "    # TODO(Mocurin): Feels really bad. Should be a way around\n",
    "    def __call__(self, *args):\n",
    "        # Probably a []-get\n",
    "        if len(args) == 1:\n",
    "            return self.__getitem__(*args)\n",
    "        # Probaly a []-set\n",
    "        if len(args) == 2:\n",
    "            return self.__setitem__(*args)\n",
    "        raise ValueError() # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем `KeyView` и `IdxView` вместе с `propery`. А еще скопируем методы для загрузки и выгрузки таблицы из предыдущей лабы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataframe:\n",
    "    def __init__(self,\n",
    "                 data: np.ndarray,\n",
    "                 columns: Union[np.ndarray, Sequence, None] = None,\n",
    "                 indices: Union[np.ndarray, Sequence, None] = None):\n",
    "        \"\"\"\n",
    "        Two-dimensional, size-immutable table.\n",
    "        \n",
    "        Contains labeled axis. Provides O(1) rows & columns access via index or key.\n",
    "        \n",
    "        Parameters\n",
    "            :data: ndarray\n",
    "                Contains rows\n",
    "            :columns: ndarray, sequence* or None\n",
    "                Contains column labels. :columns: len is required to equal data.shape[1]\n",
    "                If :columns: is None labels are filled via np.arrange on data.shape[1]\n",
    "            :indices: ndarray, sequence* or None\n",
    "                Contains row labels. :indices: len is required to equal data.shape[0]\n",
    "                If :indices: is None labels are filled via np.arrange on data.shape[0]\n",
    "            \n",
    "            *sequence (vs iterable) allows __len__, making shape checks easier.\n",
    "             Also removes intermidiate array creations for preserving one-time iterables entirely.\n",
    "            \n",
    "        Raises\n",
    "            :ValueError:\n",
    "                1) Columns/indices shape requirements are not satisfied\n",
    "                2) Recieved non-2D array as data.\n",
    "        \"\"\"\n",
    "        if len(data.shape) != 2:\n",
    "            raise ValueError(f\"2D array required. \"\n",
    "                             f\"Recieved array of {len(data.shape)} dimensions\")\n",
    "        self.data = data\n",
    "        x, y = data.shape\n",
    "        \n",
    "        def _validate_shape(seq, req_len, label: str):\n",
    "            if seq is None:\n",
    "                return np.arange(req_len)\n",
    "            if len(seq) != req_len:\n",
    "                raise ValueError(f\"Actual {label}s and recieved {label}s amount vary: \"\n",
    "                                 f\"{req_len} vs {len(seq)}\")\n",
    "            return np.array(seq)\n",
    "        \n",
    "        indices = _validate_shape(indices, x, 'row')\n",
    "        columns = _validate_shape(columns, y, 'column')\n",
    "        \n",
    "        # Construct two-way mapping for loc & iloc internal usage\n",
    "        self.col_to_loc = {col: loc for loc, col in enumerate(columns)}\n",
    "        self.columns = np.array(columns)\n",
    "        self.idx_to_loc = {idx: loc for loc, idx in enumerate(indices)}\n",
    "        self.rows = np.array(indices)\n",
    "    \n",
    "    def to_md(self):\n",
    "        \"\"\"\n",
    "        Return markdown representaion of dataframe columns & first 5 rows.\n",
    "        # TODO(Mocurin): Make `display(df)` available\n",
    "        \"\"\"\n",
    "        columns = f\"|{'|'.join(self.columns)}|\"\n",
    "        table_spec = f\"|{'|'.join([':-'] * len(self.columns))}|\"\n",
    "        rows = [f\"|{'|'.join(row)}|\" for row in self.iloc[:5]]\n",
    "        return Markdown('\\n'.join([columns, table_spec, *rows]))\n",
    "        \n",
    "    @property\n",
    "    def loc(self):\n",
    "        return KeyView(self)\n",
    "    \n",
    "    @property\n",
    "    def iloc(self):\n",
    "        return IdxView(self)\n",
    "    \n",
    "    def to_csv(self, file_path, *args, **kwargs):\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            csvfile = csv.writer(file, *args, **kwargs)\n",
    "            csvfile.writerow(self.columns)\n",
    "            csvfile.writerows(self.data.T)\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_csv(file_path, *args, **kwargs):\n",
    "        with open(file_path, 'r', newline='') as file:\n",
    "            csvfile = csv.reader(file, *args, **kwargs)\n",
    "            try: columns = next(csvfile)\n",
    "            except StopIteration: raise RuntimeError(\"File is empty\")\n",
    "            data = list(csvfile)\n",
    "            return Dataframe(np.array(data), columns)\n",
    "    \n",
    "    __getitem__ = loc\n",
    "    __setitem__ = loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем dataframe выгрузив в него данные из нулевой л/р."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|EVENT_TIME|USER_HASH|EVENT_TYPE|EVENT_TYPE_EX|AMOUNT|X2|X3|X4|X5|X6|X9|X10|X11|X12|X13|X14|X15|X16|X17|X18|X22|X23|X24|X26|COOKIE|p1_Fraud|p2_Fraud|p3_Fraud|p4_Fraud|p5_Fraud|CLASS|\n",
       "|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|\n",
       "|2015-12-15 01:09:38|7215be4441716d2f96d932ecf20e324145933912|PAYMENT|CLOSE_ACCOUNT|97207.0500|1940-06-02 00:00:00|bb64-:2c7eeb2a151:f01a1461-|f7fe0766c3|8251ac24fc|a0e4def3e5|0|0|Windows|RUB|0|0|-754|Chrome::47|491|898|12.0|80.83.236.10|Petropavlovsk|/PhizIC/private/payments/confirm.do|146521096|0.2608|0.4130|0.2845|0.3043|0.3130|G|\n",
       "|2015-12-15 01:18:24|62f4b9133f70c5d06b8789182e7728e7aa0dd7f9|PAYMENT|RURPAYJURSB|500|1981-07-11 00:00:00|f9b1-:2ea1a82a151:3b9c59-|790568bcfa|e7d835c559|a0e4def3e5|0|0|Windows|RUB|0|0|-1099|Chrome::48|-879|0|4.0|178.187.133.68|Barnaul|/PhizIC/private/payments/confirm.do|17569041|0.1233|0.2480|0.1345|0.2493|0.1480|G|\n",
       "|2015-12-15 01:19:06|62f4b9133f70c5d06b8789182e7728e7aa0dd7f9|PAYMENT|RURPAYJURSB|100|1981-07-11 00:00:00|f036-:ab3f2e2a151:8048964-|790568bcfa|e7d835c559|a0e4def3e5|0|0|Windows|RUB|0|0|-1101|Chrome::48|-875|-1522|4.0|178.187.133.68|Barnaul|/PhizIC/private/async/payments/confirm.do|10964495|0.0433|0.1520|0.0473|0.2173|0.0520|G|\n",
       "|2015-12-15 01:22:07|7215be4441716d2f96d932ecf20e324145933912|PAYMENT|RURPAYMENT||1940-06-02 00:00:00|5091-:2ea1a82a151:3b9c59-|f7fe0766c3|8251ac24fc|a0e4def3e5|0|0|Windows|RUB|0|0|-778|Chrome::47|0|0|12.0|80.83.236.10|Petropavlovsk|/PhizIC/private/async/payments/confirm.do|146521096|0.2800|0.4360|0.1360|0.3120|0.3360|G|\n",
       "|2015-12-15 01:23:01|62f4b9133f70c5d06b8789182e7728e7aa0dd7f9|PAYMENT|RURPAYJURSB|300|1981-07-11 00:00:00|063-:cc0fe32a151:0285f4b4|790568bcfa|e7d835c559|a0e4def3e5|0|0|Windows|RUB|0|0|-1099|Chrome::48|-879|898|4.0|178.187.133.68|Barnaul|/PhizIC/private/async/payments/confirm.do|10964495|0.3117|0.4740|0.3400|0.3247|0.3740|G|"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = Dataframe.read_csv(\"./fixed_data.csv\", delimiter=';')\n",
    "display(df.to_md())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем это дело:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим первые 11 рядов с колонками от `p1_Fraud` до `p5_Fraud` включительно при помощи loc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.2608', '0.4130', '0.2845', '0.3043', '0.3130'],\n",
       "       ['0.1233', '0.2480', '0.1345', '0.2493', '0.1480'],\n",
       "       ['0.0433', '0.1520', '0.0473', '0.2173', '0.0520'],\n",
       "       ['0.2800', '0.4360', '0.1360', '0.3120', '0.3360'],\n",
       "       ['0.3117', '0.4740', '0.3400', '0.3247', '0.3740'],\n",
       "       ['0.1758', '0.3110', '0.1918', '0.2703', '0.2110'],\n",
       "       ['0.3450', '0.4450', '0.5864', '0.4150', '0.6450'],\n",
       "       ['0.1242', '0.2490', '0.1355', '0.2497', '0.1490'],\n",
       "       ['0.0642', '0.1770', '0.0700', '0.2257', '0.0770'],\n",
       "       ['0.0758', '0.1910', '0.0827', '0.2303', '0.0910'],\n",
       "       ['0.0733', '0.1880', '0.0800', '0.2293', '0.0880']], dtype='<U41')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:10, 'p1_Fraud':'p5_Fraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим колонку 'CLASS' при помощи loc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['G', 'G', 'G', ..., 'F', 'F', 'F'], dtype='<U41')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, 'CLASS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим все колонки содержащие `Fraud`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.2608', '0.4130', '0.2845', '0.3043', '0.3130'],\n",
       "       ['0.1233', '0.2480', '0.1345', '0.2493', '0.1480'],\n",
       "       ['0.0433', '0.1520', '0.0473', '0.2173', '0.0520'],\n",
       "       ...,\n",
       "       ['0.6890', '0.7890', '0.8991', '0.9890', '0.9890'],\n",
       "       ['0.6900', '0.7900', '0.9000', '0.9900', '0.9900'],\n",
       "       ['0.6940', '0.7940', '0.9036', '0.9940', '0.9940']], dtype='<U41')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:, ['Fraud' in col for col in df.columns]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя fancy-indexing получим первую, третью и 10-ю колонки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['62f4b9133f70c5d06b8789182e7728e7aa0dd7f9', 'RURPAYMENT', '0'],\n",
       "      dtype='<U41')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, [1, 3, 10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим те хэши, где `p1_Fraud` > 0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "shape mismatch: indexing arrays could not be broadcast together with shapes (7837,) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-2c4cb9cb6db7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'p1_Fraud'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.66\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'USER_HASH'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'p1_Fraud'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-6b58571a7c93>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: shape mismatch: indexing arrays could not be broadcast together with shapes (7837,) (2,) "
     ]
    }
   ],
   "source": [
    "df.loc[df[:, 'p1_Fraud'].astype('float') > 0.66, ['USER_HASH', 'p1_Fraud']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется это уже загоны numpy. Не уверен что могу это пофиксить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
